{
    "componentChunkName": "component---src-templates-blog-post-js",
    "path": "/AI/gradient-descent/",
    "result": {"data":{"site":{"siteMetadata":{"title":"HelloCode"}},"markdownRemark":{"id":"0905d476-3394-57a2-a6b5-38cfd65bbff0","excerpt":"梯度下降是一种优化算法，广泛用于机器学习中，目的是通过迭代调整模型参数，最小化损失函数（即预测误差）。 核心概念 损失函数 衡量模型预测值与真实值（训练集）之间的误差，例如均方误差（MSE…","html":"<p>梯度下降是一种优化算法，广泛用于机器学习中，目的是通过迭代调整模型参数，最小化损失函数（即预测误差）。</p>\n<h2>核心概念</h2>\n<ol>\n<li>损失函数</li>\n</ol>\n<ul>\n<li>衡量模型预测值与真实值（训练集）之间的误差，例如均方误差（MSE）</li>\n<li>目标是找到一组参数，使损失函数值最小</li>\n</ul>\n<ol start=\"2\">\n<li>梯度</li>\n</ol>\n<ul>\n<li>梯度是损失函数对每个参数的偏导数，表示参数变化时损失函数的“斜率”</li>\n<li>梯度方向指向损失增加的方向，因此我们沿<strong>负梯度</strong>方向更新参数</li>\n</ul>\n<ol start=\"3\">\n<li>更新规则</li>\n</ol>\n<p>参数 w，b 的更新公式：</p>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>−</mo><mi>α</mi><mfrac><mi mathvariant=\"normal\">∂</mi><msub><mi mathvariant=\"normal\">∂</mi><mi>w</mi></msub></mfrac><mi>J</mi><mo stretchy=\"false\">(</mo><mi>w</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">w = w - α\\dfrac{∂}{∂_w}J(w,b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.4306em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6667em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.2074em;vertical-align:-0.836em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.1514em;\"><span style=\"top:-2.55em;margin-left:-0.0556em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\" style=\"margin-right:0.02691em;\">w</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.836em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow><mi>b</mi><mo>=</mo><mi>b</mi><mo>−</mo><mi>α</mi><mfrac><mi mathvariant=\"normal\">∂</mi><msub><mi mathvariant=\"normal\">∂</mi><mi>b</mi></msub></mfrac><mi>J</mi><mo stretchy=\"false\">(</mo><mi>w</mi><mo separator=\"true\">,</mo><mi>b</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">b = b - α\\dfrac{∂}{∂_b}J(w,b)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6944em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7778em;vertical-align:-0.0833em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:2.2074em;vertical-align:-0.836em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.0037em;\">α</span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.3714em;\"><span style=\"top:-2.314em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361em;\"><span style=\"top:-2.55em;margin-left:-0.0556em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mathnormal mtight\">b</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.677em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"mord\"><span class=\"mord\" style=\"margin-right:0.05556em;\">∂</span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.836em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mopen\">(</span><span class=\"mord mathnormal\" style=\"margin-right:0.02691em;\">w</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.1667em;\"></span><span class=\"mord mathnormal\">b</span><span class=\"mclose\">)</span></span></span></span></span></div>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">其中：\n- α 是学习率(learning rate)，控制每次步长大小</code></pre></div>\n<ol start=\"4\">\n<li>迭代过程</li>\n</ol>\n<ul>\n<li>初始化参数(通常随机)</li>\n<li>计算当前参数下的梯度</li>\n<li>按负梯度方向更新参数</li>\n<li>重复直到损失收敛或达到最大迭代次数</li>\n</ul>\n<h2>关键点</h2>\n<ul>\n<li>学习率 α：\n<ul>\n<li>太小：收敛慢</li>\n<li>太大：可能越过最小点，甚至发散</li>\n</ul>\n</li>\n<li>优点：通用、适合大规模数据集、可扩展到复杂模型(如神经网络)</li>\n<li>挑战：\n<ul>\n<li>可能陷入局部最小值</li>\n<li>需调参（如学习率、batch 大小）</li>\n</ul>\n</li>\n<li>收敛：当梯度接近 0 或损失变化很小时，算法停止\n<div class=\"math math-display\"><span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\" display=\"block\"><semantics><mrow></mrow><annotation encoding=\"application/x-tex\"></annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"></span></span></span></div>\n</li>\n</ul>","frontmatter":{"title":"Gradient descent","date":"April 25, 2025","description":null}},"previous":{"fields":{"slug":"/AI/linear-regression/"},"frontmatter":{"title":"Linear Regression"}},"next":null},"pageContext":{"id":"0905d476-3394-57a2-a6b5-38cfd65bbff0","previousPostId":"0ae45f8a-4e82-5487-bfdc-32eecdfd68f1","nextPostId":null}},
    "staticQueryHashes": ["2841359383","3257411868"]}